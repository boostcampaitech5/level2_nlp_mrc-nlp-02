{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. MRR 구현하기\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def mean_reciprocal_rank(contexts_or_answers, topk_docs, mean='context'):\n",
    "    \"\"\"\n",
    "    Note:\n",
    "        topk개의 docs들로부터 context/answer 기준으로 MRR을 계산합니다(context/answer 가 있는 context가 몇 번째에 있는지?)\n",
    "    Args:\n",
    "        - answers: [쿼리1 정답, 쿼리2 정답, ...], shape (쿼리 개수)\n",
    "        - docs: [[쿼리1 후보 context top k개], [쿼리1 후보 context top k개], ...], shape (쿼리 개수, topk)\n",
    "    Return:\n",
    "        MRR metric 값\n",
    "    \"\"\"\n",
    "    \n",
    "    mrr_value = 0.0\n",
    "\n",
    "    for idx, c_or_a in enumerate(contexts_or_answers):\n",
    "        for rank, doc in enumerate(topk_docs[idx]):\n",
    "            if mean == 'context':\n",
    "                # topk개의 docs들 중에서 answer를 포함하고 있는 docs가 몇 번째에 등장하는지를 계산합니다.\n",
    "                if any(re.search(c_or_a, doc)):\n",
    "                    mrr_value += 1/(rank+1)\n",
    "                    break\n",
    "            else:\n",
    "                # topk개의 docs들 중에서 원래 query-context 쌍이었던 context가 docs에서 몇 번째에 등장하는지를 계산합니다.\n",
    "                if c_or_a == doc:\n",
    "                    mrr_value += 1/(rank+1)\n",
    "                    break\n",
    "    \n",
    "    return mrr_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. NDCG 구현하기 - relevance: answer보유=1, gold_context=3\n",
    "\n",
    "def get_relevance_score(answers, gold_contexts, topk_docs):\n",
    "    \"\"\"\n",
    "    Note:\n",
    "        relevance: answer 보유=1, gold_context=3\n",
    "        \n",
    "    Arg:\n",
    "    \n",
    "    Return:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    relevance_score = []\n",
    "    \n",
    "    for idx, answer in enumerate(answers):\n",
    "        relevance_idx = []\n",
    "        gold_context = gold_contexts[idx]\n",
    "        \n",
    "        for rank, doc in enumerate(topk_docs[idx]):\n",
    "            if doc == gold_context:\n",
    "                rscore = 3\n",
    "            elif any(re.search(answer, doc)):\n",
    "                rscore = 1\n",
    "            else:\n",
    "                rscore = 0\n",
    "            relevance_idx.append(rscore)\n",
    "            \n",
    "        relevance_score.append(relevance_idx)\n",
    "    \n",
    "    return relevance_score\n",
    "\n",
    "\n",
    "def discounted_cumulative_gain(answers, gold_contexts, topk_docs, relevance=None):\n",
    "    \"\"\"\n",
    "    Note:\n",
    "    \n",
    "    Arg:\n",
    "    \n",
    "    Return:\n",
    "    \"\"\"\n",
    "    \n",
    "    DCG_values = []\n",
    "    \n",
    "    if relevance is None:\n",
    "        relevance_score = get_relevance_score(answers, gold_contexts, topk_docs)\n",
    "    else:\n",
    "        relevance_score = relevance\n",
    "    \n",
    "    for idx, _ in enumerate(answers):\n",
    "        DCG_value = 0.0\n",
    "        \n",
    "        for rank, rscore in enumerate(relevance_score[idx]):\n",
    "            DCG_value += rscore/(np.log2(2+rank))\n",
    "        \n",
    "        DCG_values.append(DCG_value)\n",
    "        \n",
    "    return DCG_values\n",
    "\n",
    "\n",
    "def normaized_discounted_cumulative_gain(answers, gold_contexts, topk_docs, relevance=None):\n",
    "    \"\"\"\n",
    "    Note:\n",
    "    \n",
    "    Arg:\n",
    "    \n",
    "    Return:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    IDCG_values = []\n",
    "    \n",
    "    if relevance is None:\n",
    "        relevance_score = get_relevance_score(answers, gold_contexts, topk_docs)\n",
    "    else:\n",
    "        relevance_score = relevance\n",
    "    \n",
    "    DCG_values = discounted_cumulative_gain(answers, gold_contexts, topk_docs, relevance=relevance_score)\n",
    "    \n",
    "    for idx, _ in enumerate(answers):\n",
    "        IDCG_value = 0.0\n",
    "        relevance_score[idx] = sorted(relevance_score[idx], reverse=True)\n",
    "        \n",
    "        for rank, rscore in enumerate(relevance_score[idx]):\n",
    "            IDCG_value += rscore/(np.log2(2+rank))\n",
    "        \n",
    "        IDCG_values.append(IDCG_value)\n",
    "        \n",
    "    NDCG_values = [dcg/idcg for dcg, idcg in zip(DCG_values, IDCG_values)]\n",
    "    NDCG_value = sum(NDCG_values)/len(NDCG_values)\n",
    "    \n",
    "    return NDCG_value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.25, 0.3333333333333333, 3.0, 1.0, 4.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = [1, 1, 3, 1, 4]\n",
    "b = sorted(a,reverse=True)\n",
    "c = [na/nb for na, nb in zip(a, b)]\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7166666666666663"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(c)/len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.917813498752873, 2.917813498752873, 2.917813498752873, 2.917813498752873, 2.917813498752873, 2.917813498752873, 2.917813498752873] [4.561606311644851, 4.561606311644851, 4.561606311644851, 4.561606311644851, 4.561606311644851, 4.561606311644851, 4.561606311644851]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6396460587368731"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevance = [0, 1, 3, 1, 0, 1, 0]\n",
    "relevance = [[0, 1, 3, 1, 0, 1, 0] for _ in range(len(relevance))]\n",
    "answers = [9 for _ in relevance]\n",
    "\n",
    "normaized_discounted_cumulative_gain(answers, _, _, relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.917813498752873 4.561606311644851 0.6396460587368731\n"
     ]
    }
   ],
   "source": [
    "# 검증\n",
    "\n",
    "dcg = 1/np.log2(2+1) + 3/np.log2(2+2) + 1/np.log2(2+3) + 1/np.log2(2+5)\n",
    "idcg = 3/np.log2(2) + 1/np.log2(2+1) + 1/np.log2(2+2) + 1/np.log2(2+3)\n",
    "\n",
    "print(dcg, idcg, dcg/idcg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
