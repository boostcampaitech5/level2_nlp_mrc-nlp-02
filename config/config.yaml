실험명: 실험명
seed: 42
CL:  # extract train extract-N extract-N-random train
# -> CL을 위한 dataset을 뽑으려면 (do_train: False, do_eval: False, model_path 지정)상태로 만들어준 후 extrat를,  
# -> CL을 하려면 True로 한 뒤 train을, CL을 하지 않으려면 None
retrieval_name: ColBERT # BM25 SparseTFIDF
retrieval_list:
  SparseTFIDF: SparseTFIDF
  BM25: SparseBM25
  ColBERT: DenseColBERT
  DenseRetrieval: DenseRetrieval
colbert_model_name:
model:
  model_name: klue/roberta-large
  model_path: # finetuning이라면 pretrained의 경로를, 아니라면 model_name을 그대로 써주세요
  num_attention_heads: 12
  attention_probs_dropout_prob: 0.1
  num_hidden_layers: 12
  hidden_dropout_prob: 0.1
  option: # question_masking, cnn, both, original
  select_option:
    question_masking: AutoModelForQuestionAnsweringAndMLM
    cnn: AutoModelForQuestionAnsweringAndCNN
    original: AutoModelForQuestionAnswering
  pretrain: # null, korquad_1.0.csv, aug_v1.csv, aug_v2.csv, korquad_1.0_noun_adj.csv
tokenizer:
  max_seq_length: 384
  pad_to_max_length: False
  doc_stride: 128
  max_answer_length: 30
option:
  overwrite_cache: False
  eval_retrieval: True
  num_clusters: 64
  top_k_retrieval: 40
  use_faiss: False
  batch_size: 16
  use_fuzz: False
  check_retrieved_score: True
wandb:
  id: gibum1228
  project: MRC
